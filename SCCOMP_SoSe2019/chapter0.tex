% !TEX root = SCCOMP.tex
% This work is licensed under the Creative Commons
% Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy
% of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/ or
% send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\chapter{Large Sparse Linear Systems}
\section{Model problems and discretization}%
\label{sec:Modelproblems and discretization}


\begin{equation}\label{eq:eq_1}\tag{1}
	\frac{\partial^2 u}{\partial x_1^2} + \frac{\partial^2 u}{\partial x_2^2} =: \laplace u = f(x) 
\end{equation}
with $\Omega \subset \R^2$ bounded, open domain and 
$ x =
\begin{pmatrix}
x_1 \\
x_2
\end{pmatrix}
\in \Omega$
\input{tikz/chapter0/example_omega.tex}
n outer normal on $\partial \Omega$
with boundary conditions
\[
\alpha u + \beta \frac{\partial u}{\partial n} = g \qquad \text{ on } \partial \Omega
.\] 

If \begin{itemize}
	\item $ \beta = 0$ and $\alpha=0$, we get a Dirichlet problem.
	\item  $\beta \neq 0$ and $ \alpha = 0$, we get a general Neumann problem.
	\item $\beta = 1$ and $\alpha = 0$, we have
		\begin{enumerate}
			\item Since $u = \text{const}$ solves \href{eq:eq_1}{(1)} 
				for $f=0 \text{ and } g = 0$, the solution to \href{eq:eq_1}{(1)} is unique up to a constant
			\item Integrating \href{eq:eq_1}{(1)} over $\Omega$ and Green's formula yield
				\[
				- \int_{\partial\Omega} \frac{\partial u}{\partial n} = - \int_{\Omega} \laplace u = \int_{\Omega} f
				.\] 
				This means, we get a compatibility condition
				\[
				\int_{\partial \Omega} g + \int_{\Omega}f = 0
				.\] 
		\end{enumerate}
\end{itemize} 

Another variant of \href{eq:eq_1}{(1)} is
\[
	Lu := \nabla(A\nabla u)
.\] 
where A is a positive definite matrix.

\begin{equation} \label{eq:eq_2}\tag{2}
LU = f \qquad \in \Omega \text{ + boundary condition}
\end{equation}

\section{Discretization with finite differences}%
\label{sec:Discretization with finite differences}

The basic idea is:

\begin{itemize}
	\item local approximation of partial derivatives
	\item derived by low order Taylor series
\end{itemize}

\begin{itemize}
	\item \underline{(1D-case):} 
		\[
			u'(x) \approx \frac{u(x+h)-u(x)}{h} = \delta^{+}u(x) \qquad \text{(forward difference)}
		.\] 
		For functions $u \in C^{4}$ in a neighbourhood of $x$, we get by Taylor's formula:
		\begin{equation} \label{eq:eq_3} \tag{$\ast$}
			u(x+h) = u(x) + h u'(x) + \frac{h^{2}}{2} u''(x) + \frac{h^{3}}{6}u'''(x) + \frac{h^{4}}{24}u''''(\xi_{+})	
		\end{equation}
		for some $\xi_{+} \in (x, x+h)$. Rearranging the equation gives
		\[
			u'(x) = \frac{u(x+h)-u(x)}{h}-\frac{h}{2}u''(x) + \O(h^{2})
		.\] 
		Now we plug this in in \href{eq:eq_4}{($\ast$)} and replace $h$ by $-h$ to get
		\begin{equation} \label{eq:eq_4} \tag{$\ast \ast$}
			u(x-h) = u(x) - hu'(x) + \frac{h^{2}}{2}u''(x)- \frac{h^{3}}{6} u'''(x) + \frac{h^{4}}{24}u''''(\xi _{-})
		\end{equation}
		For some appropriate $\xi _{-} \in (x-h, x)$.
		Adding up \href{eq:eq_3}{($\ast$)} and \href{eq:eq_4}{($\ast \ast)$} yields
		\[
			u''(x)= \frac{u(x+h) - 2u(x) + u(x-h)}{h^{2}} + \frac{h^{2}}{12}u''''(\xi )
		.\] for some $\xi  \in [\xi _{-}, \xi _{+}]$

		This is called the central difference approximation of the second order derivative.
		
		Let
		\[
			u'(x) \approx \frac{u(x)-u(x-h)}{h} = \delta^{-}u(x) \qquad \text{(backward difference)}
		.\] Then $u''(x) \approx \delta^{-}\delta^{+}u(x)$.

		For the elliptic operator $L:=\partial_{x} \Big(a(x)\partial_{x}\Big)$ we get a second order accurate formula by evaluating $a(x)$ inside the intervals $(x-h, x)$ and $(x, x+h)$
		\begin{align*}
			\partial_{x}(a(x) \partial_{x}u) &=
			\delta^{+}\Big(a(x- \frac{h}{2}) \delta^{-} u\Big) + \O(h^{2}) \\
											 &\approx \frac{a(x+\frac{h}{2})\Big(u(x+h)-u(x)\Big)-a(x-\frac{h}{2})\Big(u(x)-u(x-h)\Big)}{h^{2}}
		\end{align*}
		with $a(x \pm \frac{h}{2})$ either evaluated directly or by the average
		\[
			a(x \pm \frac{h}{2}) \approx \frac{1}{2}\Big(a(x \pm h) - a(x)\Big)
		.\] 
		
	\item \underline{(2D \& 3D cases):} 
		The laplacian is the sum of all second derivatives
		\[
			\laplace = \partial x_1^2 + \partial x_2^2 (+\partial x_3^2)
		.\] 
		With (possibly) different step width $h$ in each coordinate direction we get
		\begin{align*}
			\laplace u(x) &\approx \frac{u(x_1 + h_1, x_2) - 2u(x_1, x_2) + u(x_1 -h_1, x_2)}{h_1^2}\\
						  &+ \frac{u(x_1, x_2 + h_2) - 2u(x_1, x_2) + u(x_1, x_2 -h_2)}{h_2^2}
		\end{align*}
		but for $h_1 = h_2 = h$ we get
		\begin{align*}
			&\laplace u(x) \approx\\ 
			&\frac{1}{h^2}\left[u(x_1+ h, x_2) + u(x_1-h, x_2) + u(x_1, x_2 -h) + u(x_1, x_2 -h) -4u(x_1, x_2)\right].
		\end{align*}
		Denoting the forward/backward difference formulas
		in the direction i by $\delta_{i}^{+}$ and $\delta_{i}^{-}$ we can write
		\[
			\laplace u(x) \approx \sum_{i=1}^{2}{\delta_{i}^{+}\delta_{i}^{-}u(x)}=:\laplace_{h}^{(5)}u(x)
		.\] 
		The formula can be sketched as a stencil, the so called " 5-point stencil "
		\input{tikz/chapter0/five_point_stencil.tex}
		where the values in the nodes correspond to the coefficients in the formula.
		Other possible stencils are:
		\begin{itemize}
			\item rotated 5-point-stencil, $2^{\text{nd}}$ order accurate
				\input{tikz/chapter0/five_point_stencil_rot.tex}
			\item 9-point-stencil,  $2^{\text{nd}}$ order accurate and even $6^{\text{th}}$ order accurate for harmonic functions
				\input{tikz/chapter0/nine_point_stencil.tex}
		\end{itemize}
\end{itemize}

\section{Finite difference on a grid}%
\label{sec:Finite difference on a grid}
Let $\Omega =(0, X_{E}) \times (0,Y_{E})$ and subdivide each interval into $N_{x}+1 / N_{y} + 1$ subintervals.

\[
\left.
	\begin{array}{c}
	N_{x} = 1 \\
	N_{y} = 2
\end{array}
\right\} \qquad
h_{x} = \frac{x_{E}}{N_{x}+1}, \quad h_{y}= \frac{y_{E}}{N_{y}+1}
.\] 

\input{tikz/chapter0/fd_on_grid.tex}
Each node (vertex) in this grid is assigned an index tuple
\[
	(x,y) = (ih_{x}, jh_{y}) \stackeq{\wedge} (i,j)
.\] 
for $i \in \{0,1, \ldots , N_{x}+1\}, j \in  \{0,1, \ldots , N_{y}+1\}$

We denote the value at the node $(i,j)$ by
\[
	u(x,y)=u(ih_{x},jh_{y})=:u_{i,j}
.\] 
This results in the discrete Laplace operator $(h=h_{x}=h_{y})$
\[
	\laplace_{h}^{(5)}u_{i,j}=\frac{1}{2}(u_{i+1,j}+u_{i-1,j} +u_{i,j+1}+ u_{i,j-1} - 4u_{i,j})
.\]

\newpage
\section{Node ordering}%
\label{sec:Node ordering}
To form a linear system, the nodes $(i,j)$ have to be numbered consecutively, i.e. we have to use a map
\[
	l\colon \N^{d} \rightarrow \N
.\] 

Examples:

\begin{enumerate}[label=\alph{enumi})]
	\item  Lexicographical ordering
		\[
			l(i,j) = j \cdot (N_{x} + 2) + i 
			\quad\text{ or }\quad
			l(i,j) = i \cdot (N_{y} + 2) + j
		.\] 

		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/lexi-ordering.tex}
			\end{center}
			\caption{Lexicographical ordering}
			\label{fig:lexiorder}
		\end{figure}
		
	\item Red-Black ordering (checkerboard ordering)

		\begin{enumerate}[label=\arabic{enumii})]
			\item neighbouring nodes get different color
			\item number each node lexicographically
		\end{enumerate}

		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/red-black-ordering.tex}
			\end{center}
			\caption{Red-Black ordering}
			\label{fig:redblackorder}
		\end{figure}

		Question 1: How many colors do you need in 3D?

		Question 2: Does an analytic expression for $l(i,j)$ exist?
	\item Cache-aware ordering (Cluster nodes into connected groups)

		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/cache-ordering.tex}
			\end{center}
			\caption{Cache-aware ordering, enumeration along the arrow lines}
			\label{fig:cacheorder}
		\end{figure}
		
		This ordering scheme utilizes the fact, that data which is "located in a neighbourhood in memory respectively" can be accessed much quicker and thus fastens the operations used on the matrices.

	\item Wave front orderings (diagonal ordering)

		\begin{figure}[ht!]
			\begin{center}
				\input{tikz/chapter0/wave-ordering.tex}
			\end{center}
			\caption{Wave front ordering, enumeration along the arrow lines}
			\label{fig:waveorder}
		\end{figure}
		
\end{enumerate}

\section{Assembling}%
\label{sec:Assembling}

For the Poisson equation
\[
-\laplace u = f
.\] 
we can assemble a linear system $Au=f$ by applying the discrete operator $\laplace_{h}^{(5)}$ instead of $\laplace$ and by evaluating in the grid nodes
\[
	\begin{array}{ccl}
	A = (a_{rs}) 
	\quad&\text{ with }\quad 
	&a_{r(i,j),s(i',j')}= \frac{1}{h^{2}}\begin{cases}
		4 &\text{,if } r=s \\
		-1 &\text{,if } \abs{i-i'} = 1 \text{ and } \abs{j-j'} = 0 \\
		-1 &\text{,if } \abs{i-i'} = 0 \text{ and } \abs{j-j'} = 1 \\
		0 &\text{,otherwise}
	\end{cases} \\ \\
	f = (f_{r}) 
	\quad&\text{ with }\quad
	&f_{r(i,j)}=f(ih, jh)=f(x_{i}, y_{i})
	\end{array}
\] 
\[
	 A \stackeq{\wedge} -\laplace_{h}^{(5)}
.\] 

\section{Boundary conditions}%
\label{sec:Boundary condition}
For Dirichlet boundary condition the value $u$ at boundary nodes is fixed.

A node is boundary node if
\[
i \in  \{0, N_{x}+1\} \quad\text{ or }\quad j \in  \{0,N_{y}+1\}
.\] 

And so $u_{i,j} = g_{i,j}$ if $(i,j)$ is a boundary node.

The boundary condition can be realized by eliminating rows/columns in the matrix, i.e. let $r=l(i,j)$ a boundary index

\begin{align*}
	f &\leftarrow f-A_{\ast,r}\cdot g_{i,j} \\
	A_{r,\ast} &\leftarrow \delta_{r,s} \\
	A_{*,r} &\leftarrow \delta_{r,s} \\
	f_{r} &\leftarrow g_{i,j}
\end{align*}

\[
A\cdot \underline{u} = \underline{f}  
.\] 
\[
A = \begin{pmatrix}
	X & 
	\begin{matrix}
		0 \\
		\vdots
	\end{matrix} & X \\
	\begin{matrix}
		0 & \cdots 
	\end{matrix} & 1 &
	\begin{matrix}
		 \cdots & 0
	\end{matrix}\\
	X & \begin{matrix}
	\vdots \\
	0
	\end{matrix}
	  & X
	
	\end{pmatrix}
.\] 

\section{Structure of the matrix}%
\label{sec:Structure of the matrix}
(before eliminating the boundary conditions)
\begin{enumerate}[label=\alph{enumi})]
	\item Lexicographical ordering
		\[
		A= \frac{1}{h^{2}}
		\underbrace{
		\begin{bmatrix}
			[A_{0}] & [-I] &&& \\
			[-I] & [A_0] &&&\\
				 &&\ddots && \\
				 &&& [A_0] & [-I] \\
				 &&& [-I]& [A_0]
		\end{bmatrix}
		}_{N_{x}+2 \text{ blocks}}
		.\] 

		\[
		A_0 = \begin{bmatrix}
			4 & -1 &&& \\
			-1 & 4 & -1 && \\
			 & -1 & \ddots && \\
			 &&&\ddots & -1 \\
			 &&&-1 & 4
		\end{bmatrix}
		.\] 
	\item Red-Black ordering

		\[
			\begin{bmatrix}
				D_{r} & B \\
				B^{T} & D_{b}
			\end{bmatrix}
			\quad \text{with}\quad D_{r/b}=-\frac{1}{h^{2}}I_{r/b}
		.\] 
		B contains the values from the coupling of the nodes
\end{enumerate}

Variation of the PDE:
\[
\partial_{t}u- \laplace u=f
.\] 
Simple backward Euler scheme for $\partial_{t}$
\[
\frac{1}{\tau}u^{m+1}- \laplace u^{m+1} = f -\frac{1}{\tau}u^{m}
.\] 
with $u^{m} \equiv u(t^{m})$ with $0=t^{0}<t^{1}< \ldots  < t^{md}$ and $\tau:=t^{m+1}-t^{m}$.

The corresponding FD discretization reads:

\[
	\left(\frac{1}{\tau}I + A\right) u^{m+1} = f + \frac{1}{\tau}u^{m}
.\] 

\section{Properties of the linear system}%
\label{sec:Properties of the linear system}

\begin{definition}
\label{thm:typeOfMatrices}
	A matrix $A \in  \R^{n \times n}$ is called
	\begin{itemize}
		\item \underline{Z-matrix}, if $a_{ij}\leq 0\quad \forall i\neq j$
		\item \underline{symmetric positive definite}, if $A=A^{T}$ and $A>0$, i.e. $u^{T}Au>0\quad\forall u \in \R^{n} \setminus 0$
		\item \underline{positive definite} , if $A+A^{T}>0$
		\item \underline{M-matrix}, if $A$ is Z-matrix and $\Re(\lambda) > 0 \quad\forall \lambda \in \sigma (A)$
		\item \underline{M$_{0}$-Matrix}, if it is pos. def. and Z-matrix (M$_{0}$-matrix is an M-matrix)
	\end{itemize}
\end{definition}

\begin{definition}
\label{thm:adjacenyGraph}
Let $A$ be a (sparse) matrix. The graph $G_{A}=(V,E)$ with $E \subset V \times V$ is called \underline{adjacency graph} of $A$ if 
\begin{itemize}[label=]
	\item $V$ represents the $n$ unknowns/rows/columns
	\item $V=\{1, \ldots, n\}$
	\item $E=\{(i,j) \in  V \times V : a_{ij}\neq 0\}$
\end{itemize}
(The edges represent the relation: equations $i$ involves unknown $j$)
\end{definition}

\begin{definition}
\label{thm:irreducible}
A matrix $A$ is called \underline{irreducible} if for $G_{A}=(V,E)$:
\[
	\forall i,j \in V ~:~ \exists \text{ sequence of edges } (e_0, e_1, \ldots , e_{n}) \subset E
\] 
such that
\[
	e_0=(i, k_0), e_1=(k_0,k_1),\ldots , e_{m}=(k_{m-1},j) \quad \text{with } k_{j} \in V
.\] 

(All vertices are connected by a sequence of edges)
\[
	\mathcal{IR}:= \{A \in  \R^{n \times  n} | A \text{ is irreducible}\}
.\] 
\end{definition}

\begin{definition}
\label{thm:WDDmatrices}
\begin{align*}
	WDD:= &\left\{ A \in \R^{n \times n}, \abs{a_{j,j}}  \geq \sum_{i\neq j}^{}{\abs{a_{i,j}} } \quad \forall j \right\}  \\
		 = &\left\{ A \in R^{n \times }, \abs{a_{i,i}} \geq \sum_{i\neq j}^{}{\abs{a_{i,j}} } \quad \forall i \right\} 
\end{align*}
are the weakly diagonal dominant matrices.
\[
DD:= \left\{ A \in WDD, \exists j : ">" \right\} 
\] 
are diagonal dominant matrices.
\[
SDD := \left\{ A \in WDD, \forall j : ">" \right\} 
\] 
are the strictly diagonal dominant matrices.
\[
IDD := \left\{ A \in DD, A \text{ is irreducible} \right\} 
\] 
are the irreducible diagonal dominant matrices.
\end{definition}

\begin{theorem}(Gershgorin)
\label{thm:gershgorin}
Any eigenvalue $\lambda \in \sigma (A)$ is located in one of the closed discs in the complex plane centered at $a_{i,i}$ and having the radius
\[
	\rho_{i} = \sum_{\substack{j=0 \\ j \neq i}}^{n}{\abs{a_{i,j}} }
.\] 
In other words : 
\[
	\forall \lambda \in \sigma (A) \exists i \text{ such that } \abs{\lambda - a_{i,i}}  \leq \sum_{\substack{j=0 \\ j \neq i}}^{n}{\abs{a_{i,j}} }
.\] 
\end{theorem}

\begin{proof}
\label{thm:gershgorinproof}
	Let $x$ be an eigenvector associated to eigenvalue $\lambda$ and let $m$ be the index of the component with largest modulus in $x$.

	Scale $x$, s.t.
	\[
	\abs{x_{m}}  = 1 \text{ and } \abs{x_{i}} \leq 1 \quad \forall i \neq m
	.\] 
	Since $x$ is an eigenvector to $A$, we have
	\[
		(\lambda - a_{n,m}) x_{m} = - \sum_{\substack{j=1 \\ j \neq m}}^{n}{\abs{a_{m,j}} x_{j}}
	.\] 
	Taking the absolute value of this, we get
	\[
		\abs{\lambda - a_{m,m}}  \leq \sum_{j\neq m}^{}{\abs{a_{m,j}} \abs{x_{j}} } \leq \sum_{j\neq m}^{}{\abs{a_{m,j}} } = \rho_{m}
	.\] 
\end{proof}
\input{tikz/chapter0/gershgorin_disks.tex}
\begin{theorem}
\label{thm:gershgorinboundary}
	Let $A$ be irreducible and assume that an eigenvalue $\lambda$ lies on the boundary of the union of all Gershgorin discs. Then $\lambda$ lies on the boundary of all Gershgorin discs.
\end{theorem}

\begin{proof}
\label{thm:gershgorinboundaryproof}
	Iterate proof of \href{thm:gershgorinproof}{the last proof} along the connecting edges of any pairs of nodes. Do this for all pairs and you get the result.
\end{proof}

\begin{corollary}
\label{thm:gershgorinboundarycorollary1}
	If $A$ is strictly diagonal dominant or $A$ is irreducible diagonal dominant, then $A$ is non-singular.
\end{corollary}

\begin{proof}
\label{thm:gershgorinboundarycorollary1proof}
	\begin{enumerate}[label=\alph{enumi})]
		\item Assume $A \in SDD$.

			Then the Gershgorin discs exclude the origin. This means $\lambda =0$ cannot be an eigenvalue of $A$.

		\item Assume $A \in IDD$.

			Then if it is singular, the zero eigenvalue lies on the boundary of the union of the Gershgorin discs. Together with \href{thm:gershgorinboundary}{Theorem 2} this implies that the eigenvalue should be located on the boundary of all discs.
			\[
				\implies \abs{a_{j,j}} = \sum_{i \neq j}^{}{\abs{a_{i,j}} } \qquad \forall j=0, \ldots , n
			.\] 
			$\lightning$, since $A$ is diagonal dominant.
	\end{enumerate}
\end{proof}

\begin{corollary}
\label{thm:gershgorinboundarycorollary2}
	Let $A \in R^{n \times  n}$. If 
	\[
		A \in WDD \text{ and } A = A^{T} \text{ and } \text{diag}(A) \geq 0
	,\] 
	then $A$ is pos. semidefinite. 
\end{corollary}

\begin{proof}
\label{thm:gershgorinboundarycorollary2proof}
\begin{align*}
& A \text{ symmetric} \\
	\implies & \text{ eigenvalues are real} \\
	\overset{(\ast)}{\implies} & \forall \lambda  \in \sigma (A) : \lambda  \geq 0
\end{align*}
[with $(\ast) = \text{diag(A)} \geq 0 + A \in WDD + $ \href{thm:gershgorin}{Theorem 1}] 
\end{proof}

\begin{summary}
\label{thm:summarymatrices}
The matrix $A = \laplace_{h}^{(5)}$ is 
\begin{itemize}
	\item symmetric $A = A^{T}$
	\item $A \in WDD$
	\item For Dirichlet boundary conditions we even have $A \in DD$
	\item irreducible
	\item $\text{diag}(A) \geq 0$
\end{itemize}
	$\implies A$ is positive definite and $A$ is $M_0$-matrix and thus $M$-matrix.
\end{summary}

\section{The non-zero structure of the matrix}%
\label{sec non-zero structure of the matrix}

A matrix $A \in \R^{n \times n}$ is called \underline{sparse matrix}, if the number of non-zero entries $(a_{i,j}\neq 0)$ is $\ll n^2$. Otherwise it is called a \underline{full matrix}. 

\begin{definition}
\label{thm:sparsetypes}
A (sparse) matrix is called a \underline{banded matrix}  with bandwidth $M$ if
\[
a_{i,j}\neq 0 \text{ only if } i-m_{l} \leq j \leq i + m_{n}
.\] 
with $m_{l},m_{n} \in \N_{>0}$ the lower and upper bandwidth and $M:=m_{l} + m_{n} + 1$.
\end{definition}

What is the bandwidth of $\laplace_{h}^{(5)}$? (using lexicographical ordering)

\begin{align*}
\begin{bmatrix}
	x & x &   &   & \\
	x & x & x &   & \\
	  & x & x & x & \\
	  &   & x & x & \\
	  &   &   &   & \ddots
\end{bmatrix}
\begin{bmatrix}
	x &   &   &   & \\
	  & \ddots &   &   & \\
	  &   & \ddots &   & \\
	  &   &   & \ddots & \\
	  &   &   &   & x
\end{bmatrix} \\
\underbrace{ 
\begin{bmatrix}
	x &   &   &   & \\
	  & \ddots &   &   & \\
	  &   & \ddots &   & \\
	  &   &   & \ddots & \\
	  &   &   &   & x
\end{bmatrix}}_{N_{x}+2}
\underbrace{ 
\begin{bmatrix}
	x & x &   &   & \\
	x & x & x &   & \\
	  & x & x & x & \\
	  &   & x & x & \\
	  &   &   &   & \ddots
\end{bmatrix}}_{A_0}
\end{align*}

The bandwidth of $A_0$ is 3.
We can deduce the other constants with this information:
\begin{itemize}
	\item $m_{l}=m_{n}=N_{x}+2 (\text{ or } N_{y}+2)$
	\item the boundary width of $A$ is $\O(n^{\frac{1}{2}})$ in 2D.
\end{itemize}

What is the number of non-zeros in $\laplace_{h}^{(5)} $?

\[
	nnz(A) \approx 5 \cdot n = 5(N_{x} +2)(N_{y} +2)
.\] 

\section{Finite Difference Refinement}%
\label{sec:Finite Difference Refinement}

Denote by $\Omega_{h}$ the mesh of grid points of width $h$, i.e. 
\[
	(x_{i}, y_{j}) = (ih, jh)
\] 
and by $\Omega_{H}$ the mesh of grid points with width $H$. Assume here $H=2h$.

\input{tikz/chapter0/grid_h_H.tex}

Given a discrete solution $u^{h}$ at $\Omega_{h}$, how to transfer the values to a coarser/finer mesh?

Answer: Use Interpolation!

The transfer from fine mesh $\Omega_{h}$ to coarse mesh $\Omega_{H}$ is called "\underline{Restriction}", denoted by $R_{h}^{H}$ and the transfer from coarse to fine mesh is called "Prolongation" denoted by $P_{H}^{h}$.
\[
R_{h}^{H}: \Omega_{h} \rightarrow \Omega_{H}, \quad
P_{H}^{h}: \Omega_{H} \rightarrow \Omega_{h}
.\] 

\begin{enumerate}[label=\Alph{enumi})]
	\item Prolongation:
		\begin{enumerate}[label=\underline{\arabic{enumi}D}]
			\item The simplest operator is defined by polynomial (linear) interpolation
		%TODO plot 1D interpolation Linie.
		\input{tikz/chapter0/grid_stencil_1D.tex}
		%\begin{figure}[ht!]
		%	\begin{center}
				%\includegraphics[width=0.5\textwidth]{pics/}
		%	\end{center}
		%	\caption{1D}
		%	\label{fig:prolongation1}
		%\end{figure}
		\begin{align*}
			u_{2j}^{h} &= u_{j}^{H}  &\text{ for } j=0, \ldots, \frac{N+1}{2} \\
			u_{2j+1}^{h} &= \frac{1}{2}(u_{j}^{H}+u_{j+1}^{H})
		\end{align*}
		In matrix form, we obtain
		\[
		u^{h}= \frac{1}{2}\begin{bmatrix}
			1& & & & \\
			2& & & & \\
			1&1& & & \\
			 &2& & & \\
			 &1&1& & \\
			 & &2& & \\
			 & &1& & \\
			 & & &\ddots& \\
			 & & & &1 \\
			 & & & &2 \\
			 & & & &1
		\end{bmatrix}u^{H}
		.\] 
		Because of the specific coefficients, the interpolation is denoted in a stencil form by
		\[
			P_{H}^{h} \overset{\wedge}{=} \frac{1}{2}
			\left]
			\begin{matrix}
				1 & 2 & 1	
			\end{matrix}
			\right[
		.\] 

	\item The interpolation can be done in each coordinate direction.
		We get a tensor-product of the two 1D rules
		\begin{align*}
			u_{2i, 2j}^{h} &= u_{i,j}^{H} &i=0, \ldots, \frac{N_{x}+1}{2} \\
			u_{2i+1, 2j}^{h} &= \frac{1}{2}(u_{i,j}^{H}+u_{i+1,j}^{H}) &j=0, \ldots, \frac{N_{y}+1}{2} \\
			u_{2i,2j+1}^{h} &= \frac{1}{2}(u_{i,j}^{H}+u_{i,j+1}^{H}) \\
			u_{2i+1, 2j+1}^{h} &= \frac{1}{4}(u_{i,j}^{H}+ u_{i+1,j}^{H}+ u_{i,j+1}^{H}+ u_{i+1,j+1}^{H})
		\end{align*}
		In stencil form we get
		\[
			P_{H}^{h} \overset{wedge}{=} \frac{1}{4}
			\left]
			\begin{matrix}
				1 & 2 & 1 \\
				2 & 4 & 2 \\
				1 & 2 & 1 
			\end{matrix}
			\right[
		.\] 
		\input{tikz/chapter0/grid_stencil_2D.tex}
		Note: if you interpret the 1D stencil as a row vector $p^{T}$, the 2D stencil is just the outer product 
		\[
		p\cdot p^{T}
		.\] 
		Note: higher order interpolation rules are possibly by incorporating more coarse grid rules.
		\end{enumerate}
		

\end{enumerate}

