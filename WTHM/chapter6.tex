% This work is licensed under the Creative Commons
% Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy
% of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/ or
% send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\chapter{Fouriertransformation und charakteristische Funktionen} %6
Ziel: Mit Zufallsvariablen analytisch / deterministisch zu rechnen \nl
Wichtige Anwendungen:
\begin{itemize}
	\item Charakterisierung von Unabhängigkeit
	\item schwache Konvergenz
	\item Zentrale Grenzwertsätze
\end{itemize}

\begin{defi}\
	\begin{enumerate}[label=(\alph*)]
		\item Für $\mu\in\mathcal{M}_b(\R^d)$ (beschränkte Borelmaße auf $\R^d$) ist die \textbf{Fouriertransformation (FT)} definiert als
		\begin{align*}
			\hat{\mu}:\R^d\to\C,\qquad
			\hat{\mu}(\xi):=\int\limits_{\R^d}\exp(i\cdot\xi^T\cdot x)~\mu(\d x)\qquad\forall\xi\in\R^d
		\end{align*}
		\item Für $f\in L_1(\R^d,\d x)$ ist die \textbf{FT} definiert als
		\begin{align*}
			\hat{f}:\R^d\to\C,\qquad
			\hat{f}(\xi):=\int\limits_{\R^d}\exp(i\cdot\xi^T\cdot x)\cdot f(x)\d x\qquad\forall\xi\in\R^d
		\end{align*}
		\item Für Zufallsvariable $X:\Omega\to\R^d$ ist die \textbf{charakteristische Funktion (CF)} definiert als
		\begin{align*}
			\Phi_X:\R^d\to\C,\qquad
			\Phi_X(\xi):=\E\Big[\exp\big(i\cdot X^T\cdot\xi\big)\Big]\qquad\forall\xi\in\R^d
		\end{align*} 
	\end{enumerate}
\end{defi}

\begin{bemerkung}
	(a) ist die allgemeinste Definition. (b) und (c) können als Spezialfälle betrachtet werden:
	\begin{enumerate}[label=(\alph*):]
		\setcounter{enumi}{1}
		\item Setze $\mu(\d x):=f(x)\d x$, d.h. $f$ ist Dichte von $\mu$ bzgl. Lebesgue-Maß. Damit gilt:
		\begin{align*}
			\hat{\mu}(\xi)
			&=\int\limits_{\R^d}\exp(i\cdot x^T\cdot\xi)~\mu(\d x)
			=\int\limits_{\R^d}\exp(i\cdot x^T\cdot\xi)\cdot f(x)\d x=\hat{f}(\xi)
		\end{align*}
		\item Sei $\P_X$ Bildmaß von $X$ unter $\P$ (d.h. Wahrscheinlichkeitsmaß auf $\R^d$). Dann gilt:
		\begin{align*}
			\hat{\mu}(\xi)=\int\limits_{\R^d}\exp(i\cdot x^T\cdot\xi)~\P_X(\d x)=\E\big[\exp(i\cdot X^T\cdot\xi)\big]
			=\Phi_X(\xi)
		\end{align*}
	\end{enumerate}
	Weitere Notation: 
	\begin{align*}
		\hat{\mu}=:\F(\mu)\qquad\hat{f}=:\F(f)
	\end{align*}
	Hier steht $\F$ also nicht für eine $\sigma$-Algebra, sondern für die Fouriertransformation.
	Die Schreibweise ist günstig, um große ``Dächer'' zu vermeiden. 
\end{bemerkung}

\begin{beisp}\
	\begin{enumerate}[label=(\alph*)]
		\item Sei $X\sim\mathcal{N}(0,1)$. Folglich ist
		\begin{align*}
			\Phi_X(\xi)=\exp\left(-\frac{\xi^2}{2}\right)
		\end{align*}
		denn:
		\begin{align*}
			\Phi_X(\xi)
			&=\int\limits_{-\infty}^\infty \exp(i\cdot x\cdot\xi)\cdot\frac{1}{\sqrt{2\cdot\pi}}\cdot\exp\left(-\frac{x^2}{2}\right)\d x\\
			\Phi_X'(\xi)
			&=\frac{1}{\sqrt{2\pi}}\cdot\int\limits_{-\infty}^\infty i\cdot x\cdot\exp\left(i\cdot x\cdot\xi-\frac{x^2}{2}\right)\d x\\
			&=i\cdot\frac{1}{\sqrt{2\cdot\pi}}\cdot\int\limits_{-\infty}^\infty\exp(i\cdot x\cdot\xi)\cdot\underbrace{x\cdot\exp\left(-\frac{x^2}{2}	\right)}_{=-\frac{\partial}{\partial x}\exp\left(-\frac{x^2}{2}\right)}\\
			&=\underbrace{\left[-i\cdot\frac{1}{\sqrt{2\cdot\pi}}\cdot\exp(i\cdot x\cdot\xi)\cdot\exp\left(-\frac{x^2}{2}\right)\right]_{-\infty}^\infty}_{=0}\\
			&\qquad-\xi\cdot\underbrace{\frac{1}{\sqrt{2\cdot\pi}}\cdot\int\limits_{-\infty}^\infty\exp(i\cdot x\cdot\xi)\cdot\exp\left(-\frac{x^2}{2}\right)\d x}_{=\Phi_X(\xi)}\\
			&=-\xi\cdot\Phi_X(\xi)\\
		\end{align*}
		Also erfüllt $\Phi_X(\xi)$ die gewöhnliche Differentialgleichung
		\begin{align*}
			\Phi_X'(\xi)=-\xi\cdot\Phi_X(\xi),\qquad\Phi_X(0)=1
		\end{align*}
		Eindeutige Lösung ist $\Phi_X(\xi)=\exp\left(-\frac{\xi^2}{2}\right)$.\nl
		\textbf{Merke:} Die Charakteristische Funktion der Standardnormalverteilung ist proportional zu ihrer Dichte.
		\item Sei $X\sim\mathcal{N}(0,I_d)$ multivariat. Dann haben wir
		\begin{align*}
			\Phi_X(\xi)
			&=\E\Big[\exp(i\cdot\xi^T\cdot X)\Big]\\
			&=\E\left[\prod\limits_{j=1}^d\exp(i\cdot\xi_j\cdot X_j)\right]\\
			\overset{(X_j)\text{ unab}}&=
			\prod\limits_{j=1}^d\underbrace{\E\Big[\exp(i\cdot\xi\cdot X_j)\Big]}_{=\Phi_{X_j}(\xi_j)}\\
			&=\prod\limits_{j=1}^d\exp\left(-\frac{\xi_j^2}{2}\right)\\
			&=\exp\left(-\frac{\xi^T\cdot\xi}{2}\right)\\
			&=\exp\left(-\frac{|\xi|^2}{2}\right)
		\end{align*}
	\end{enumerate}
\end{beisp}

\begin{theorem}[Eigenschaften der FT / CT]\label{theorem6.1EigenschaftenDerFTCF}\enter
	Sei $\mu\in\mathcal{M}_b(\R^d)$ bzw. $X:\Omega\to\R^d$ eine Zufallsvariable. Dann gilt:
	\begin{enumerate}[label=(\alph*)]
		\item $\begin{aligned}
			\hat{\mu}(0)=\mu(\R^d)\qquad\text{bzw.}\qquad\Phi_X(0)=1
		\end{aligned}$
		\item $\begin{aligned}
			\big|\hat{\mu}(\xi)\big|\leq\mu(\R^d)\qquad\text{bzw.}\qquad\big|\Phi_X(\xi)\big|\leq 1 \qquad\forall\xi\in\R^d
		\end{aligned}$ (Beschränktheit)
		\item $\xi\mapsto\hat{\mu}(\xi)$ bzw. $\xi\mapsto\Phi_X(\xi)$ ist stetig
		\item $\begin{aligned}
			\hat{\mu}(-\xi)=\overline{\hat{\mu}(\xi)}\qquad\text{bzw.}\qquad\Phi_X(-\xi)=\overline{\Phi_X(\xi)}\qquad\forall\xi\in\R^d
		\end{aligned}$ (Hermitsch-Symmetrie)
		\item Sei $T(x)=A\cdot x+b$ eine lineare Transformation mit $A\in\R^{m\times d}$ und $b\in\R^m$. Dann gilt:
		\begin{align*}
			\F\left(\mu\circ T^{-1}\right)(\xi)&=\exp\left(i\cdot b^T\cdot\xi\right)\cdot\hat{\mu}\left(A^T\cdot\xi\right)
			&\forall&\xi\in\R^m\text{ bzw.}\\
			\Phi_{(A\cdot X+b)}(\xi)
			&=\exp\left(i\cdot b^T\cdot\xi\right)\cdot\Phi_X\left(A^T\cdot\xi\right)
			&\forall&\xi\in\R^m
		\end{align*}
	\end{enumerate}
\end{theorem}

\begin{proof}
	\underline{Zu (a):}
	\begin{align*}
		\hat{\mu}(0)&=\int\limits_{\R^d}1~\mu(\d x)=\mu(\R^d)
	\end{align*}
	\underline{Zu (b):}
	\begin{align*}
		\Big|\hat{\mu}(\xi)\Big|
		&=\left|\int\limits_{\R^d}\exp(i\cdot x^T\cdot\xi)~\mu(\d x)\right|\\
		&\leq
		\int\limits_{\R^d}\underbrace{\Big|\exp(i\cdot x^T\cdot\xi)\Big|}_{=1}~\mu(\d x)
		=\mu(\R^d)
	\end{align*}
	\underline{Zu (c):}\\
	$\xi\mapsto\exp(i\cdot x^T\cdot\xi)$ ist stetig für alle $x$ und $\Big|\exp(i\cdot x^T\cdot\xi)\Big|\leq1$.
	Somit folgt aus dominierter Konvergenz die Stetigkeit von
	\begin{align*}
		\xi\mapsto\int\limits\exp\left(i\cdot x\cdot\xi\right)~\mu(\d x).
	\end{align*}
	\underline{Zu (d):}
	\begin{align*}
		\hat{\mu}(-\xi)
		&=\int\limits_{\R^d}\exp(-i\cdot x^T\cdot\xi)~\mu(\d x)\\
		&=\int\limits_{\R^d}\overline{\exp(i\cdot x^T\cdot\xi)}~\mu(\d x)\\
		&=\overline{\int\limits_{\R^d}\exp(i\cdot x^T\cdot\xi)~\mu(\d x)}\\
		&=\overline{\hat{\mu}(\xi)}
	\end{align*}
	\underline{Zu (e):}
	\begin{align*}
		\F\left(\mu\circ T^{-1}\right)(\xi)
		&=\int\limits_{\R^d}\exp(i\cdot\xi^T\cdot x)~\big(\mu\circ T^{-1}\big)(\d x)\\
		\overset{\text{Trafo}}&=
		\int\limits_{\R^d}\exp\big(i\cdot\xi^T\cdot T(x)\big)~\mu(\d x)\\
		&=\int\limits_{\R^d}\exp\left(i\cdot\xi^T\cdot (A\cdot x)+i\cdot\xi^T\cdot b\right)~\mu(\d x)\\
		&=\exp\left(i\cdot\xi^T\cdot b\right)\cdot\int\limits_{\R^d}\exp\left(i\cdot(A^T\cdot\xi)^T\cdot x\right)~\mu(\d x)\\
		&=\exp\left(i\cdot\xi^T\cdot b\right)\cdot\hat{\mu}\left(A^T\cdot\xi\right)
	\end{align*}
	Alle Aussagen für $X$ folgen als Spezialfall $\mu=\P_X$.
\end{proof}

\begin{beisp}[Multivariate Normalverteilung]\enter
	Sei $X\sim\mathcal{N}(0,I_d)$, $\mu\in\R^d$, $\Sigma\in\R^{d\times d}$ positiv semidefinit mit $\Sigma=A^T\cdot A$ 
	(z. B. \textit{Cholesky-Zerlegung}). 
	Dann gilt:
	\begin{align*}
		Y&:=\underbrace{\mu+A\cdot X}_{=T(X)}\sim\mathcal{N}(\mu,\Sigma)\\
		\overset{\ref{theorem6.1EigenschaftenDerFTCF}}{\implies}
		\Phi_Y(\xi)&=\exp\left(i\cdot\mu^T\cdot \xi\right)\cdot\Phi_X\left(A^T\cdot\xi\right)\\
		&=\exp\left(i\cdot\mu^T\cdot\xi-\frac{1}{2}\cdot\xi^T\underbrace{ A\cdot A^T}_{=\Sigma}\xi\right)\\
		&=\exp\left(-i\cdot\mu^T\cdot\xi-\frac{1}{2}\cdot\xi^T\cdot\Sigma\cdot\xi\right)
	\end{align*}
	Das ist die CF von $\mathcal{N}(\mu,\Sigma)$.
\end{beisp}

\begin{beisp}
	Einige Verteilungen mit expliziter charakteristischer Funktion (mit $q:=1-p$).\nl
	\begin{tabular}{l|l|c}
		Verteilung & Dichte $f$ / W-Funktion $p_k=\P(X=k)$ & CF $\Phi_X(u)$\\ \hline\hline
					 &&\\
		Binomialvtl. $p,n$ & $p_k=\begin{pmatrix}
			n\\ k
		\end{pmatrix}\cdot p^k\cdot q^{n-k},~k=0,\ldots, n$ & $\big(p\cdot\exp(i\cdot k)+1\big)^n$\\&&\\ \hline &&\\
		Poissonvtl. $\lambda$ & $p_k=\exp(-\lambda)\cdot\frac{\lambda^k}{k!}~kk\in\N_0$ & $\exp\big(\lambda\cdot(\exp(i\cdot u)\big)$ \\ &&\\ \hline &&\\
		geom. Vert. $p\in(0,1)$ & $p_k=q^{k-1}\cdot p,~k\in\N$ & $\frac{p\cdot\exp(i\cdot u)}{1-q\cdot\exp(i\cdot u)}$ \\ &&\\ \hline &&\\
		Exponentialvtl. $\lambda>0$ & $f(x)=\lambda\cdot\exp(-\lambda\cdot x),~x\geq0$ & $\frac{\lambda}{\lambda-i\cdot u}$\\ &&\\ \hline &&\\
		Std. Normalvtl. & $f(x)=\frac{1}{\sqrt{2\cdot \pi}}\cdot\exp\left(-\frac{x^2}{2}\right)$ & $\exp\left(-\frac{u^2}{2}\right)$\\ &&\\ \hline &&\\
		Lalplace-Vert. & $f(x)=\frac{1}{2}\cdot\exp\big(-|x|\big)~x\in\R$ & $\frac{1}{1+u^2}$\\ &&\\ \hline &&\\
		Gleichvtl. auf $[-1,1]$ & $f(x)=\frac{1}{2}\cdot\indi_{[-1,1]}(x)$ & $\frac{\sin(u)}{u}$\\ &&\\ \hline &&\\
		Cauchyvtl. & $f(x)=\frac{1}{\pi}\cdot\frac{1}{1+x^2}$ & $\exp\big(-|u|\big)$
	\end{tabular}
\end{beisp}

Als nächstes: partielle Ableitungen von charakteristischen Funktionen.

\begin{notation}
	Kompakte Notation: \textbf{Multiindex (MI)} ist
	\begin{align*}
		\alpha=\big(\alpha_1,\ldots,\alpha_d\big)\in\N_0^d
	\end{align*}
	Für MIs $\alpha,\beta\in\N_0^d$ und $x\in\R^d$ definieren wir:
	\begin{itemize}
		\item $\begin{aligned}
			|\alpha|:=\alpha_1+\ldots+\alpha_d
		\end{aligned}$ ist die \textbf{Ordnung} des MI $\alpha$
		\item Setze weiterhin
		\begin{align*}
			\alpha!&:=\alpha_1!\cdot\alpha_2!\cdot\ldots\cdot\alpha_d!\\
			x^\alpha&:=x_1^{\alpha_1}\cdot x_2^{\alpha_2}\cdot\ldots\cdot x_d^{\alpha_d}
		\end{align*}
		\item $\begin{aligned}
			\beta\leq\alpha:\Longleftrightarrow(\beta_1\leq\alpha_1)\wedge(\beta_2\leq\alpha_2)\wedge\ldots\wedge(\beta_d\leq\alpha_d)
		\end{aligned}$ 
		\item Falls $\beta\leq\alpha$ definiere
		\begin{align*}
			\alpha-\beta:=\big(\alpha_1-\beta_1,\ldots,\alpha_d-\beta_d\big)\\
			\begin{pmatrix}
				\alpha\\\beta
			\end{pmatrix}&:=\begin{pmatrix}
				\alpha_1\\\beta_1
			\end{pmatrix}\cdot\begin{pmatrix}
				\alpha_2\\\beta_2
			\end{pmatrix}\cdot\ldots\cdot\begin{pmatrix}
				\alpha_d\\\beta_d
			\end{pmatrix}
		\end{align*}
		\item gemischte partielle Ableitung:
		\begin{align*}
			\partial^\alpha:=\partial_x^\alpha:=\frac{\partial^{|\alpha|}}{\partial_{x_1}^{\alpha_1}\partial_{x_2}^{\alpha_2}\ldots\partial_{x_d}^{\alpha_d}}
		\end{align*}
	\end{itemize}
\end{notation}

Mit Multiindexschreibweise gilt:
\begin{enumerate}
	\item \textbf{Taylorentwicklung:} Für $f:\R^d\to\C$ analytisch in $B_R(x_0)$ gilt:
	\begin{align}\label{eqTaylor}\tag{Taylor}
		f(x)=\sum\limits_{\alpha\in\N_d}\partial^\alpha f(x_0)\cdot\frac{(x-x_0)^\alpha}{\alpha!}\qquad\forall x\in B_R(x_0)
	\end{align}
	\item \textbf{Leibnizregel:} Für $f,g\in C^\alpha(\R^d,\C)$ gilt:
	\textbf{\begin{align}\label{eqLeibnizregel}\tag{Leibniz}
		\partial^\alpha(f\cdot g)=\sum\limits_{\begin{subarray}{c}
			\beta\leq\alpha\\ \beta\in\N_0^d
		\end{subarray}}
		\begin{pmatrix}
			\alpha\\\beta
		\end{pmatrix}\cdot\partial^\beta f\cdot\partial^{\alpha-\beta}g
	\end{align}
	%Hinweis für Übung: Induktion über Länge des MI}
	\item \textbf{Ableitung einer Funktion:}
	\begin{align*}
		\partial_x^\alpha\Big(\exp\big(b^T\cdot x\big)\Big)=b^\alpha\cdot\exp\big(b^T\cdot x\big)\qquad\forall x,b\in\R^d
	\end{align*}}
\end{enumerate}

\begin{theorem}\label{theorem6.2}
	Sei $k\in\N_0$ und $X\colon\Omega\to\R^d$ Zufallsvariable mit $\E\big[|X|^k\big]<\infty$.\\
	Dann existiert die charakteristische Funktion $\partial^\alpha\Phi_X$ für alle MI $\alpha\in\N_0^d$ mit $|\alpha|\leq k$ und
	\begin{align}\label{eqTheorem6.2}\tag{$\ast$}
		\E\big[X^\alpha\big]=(-i)^{|\alpha|}\cdot\partial^\alpha\Phi_X(0)
	\end{align}
	Hierbei heißt
	\begin{align*}
		\E\big[X^\alpha\big]=\E\Big[X_1^{\alpha_1}\cdot X_1^{\alpha_2}\cdot\ldots\cdot X_d^{\alpha_d}\Big]
	\end{align*}
	\textbf{gemischtes Moment} und
	\begin{align*}
		\partial^\alpha\Phi_X(0)
	\end{align*} heißt \textbf{gemischte partielle Ableitung} an der 0.
\end{theorem}

\begin{proof}
	\underline{Zeige Existenz von $\E\big[X^\alpha\big]$:}
	\begin{align*}
		\big|X^\alpha\big|
		&=\big|X_1^{\alpha_1}\cdot X_2^{\alpha_2}\cdot\ldots\cdot X_d^{\alpha_d}\big| \\
		&=\big|X_1^{\alpha_1}\big|\cdot\ldots\cdot\big|X_d^{\alpha_d}\big| \\
		&\leq\big|X_1\big|^{\alpha_1}\cdot\ldots\cdot\big|X_d\big|^{\alpha_d} \\
		&=\big|X\big|^{|\alpha|}
	\end{align*}
	Daraus folgt durch Bildung von Erwartungswerten
	\begin{align*}
		\E\Big[\big|X^\alpha\big|\Big]
		&\leq
		\E\Big[\big|X^{|\alpha|}\big|\Big] \\
		&\leq
		\E\Big[\big(1+|X|\big)^{|\alpha|}\Big] \\
		\overset{|\alpha|\leq k}&{\leq}
		\E\Big[\big(1+|X|\big)^k\Big] \\
		&\leq 2^{k-1}\cdot\Big(1+\E\big[|X|^k\big]\Big)<\infty
	\end{align*}
	\underline{Zeige \eqref{eqTheorem6.2}:}
	\begin{align*}
		\partial^\alpha\Phi_X(\xi)
		&=\partial^\alpha\E\Big[\exp(i\cdot\xi^T\cdot X)\Big]\\
		&=\E\Big[\partial^\alpha_\xi\exp(i\cdot\xi^T\cdot X)\Big]\\
		&=\E\Big[(i\cdot X)^\alpha\cdot\exp(i\cdot\xi^T\cdot X)\Big]\\
		&=i^{|\alpha|}\cdot\E\Big[X^\alpha\cdot\exp(i\cdot\xi^T\cdot X)\Big]
	\end{align*}
	Auswerten an der Stelle $\xi=0$ liefert:
	\begin{align*}
		\partial^\alpha\Phi_X(0)=i^{|\alpha|}\cdot\E\Big[X^\alpha\Big]
	\end{align*}
\end{proof}

\begin{bemerkung}
	Die Umkehrung in Theorem \ref{theorem6.2} gilt i.A. nicht.\\
	Aber: In Dimension $d=1$ gilt:
	\begin{align*}
		\partial^{2\cdot k}\Phi_X(0)\text{ existiert}\implies\E\Big[X^{2\cdot k}\Big]<\infty\text{ und }\E\Big[X^m\Big]=\partial^m\Phi_X(0)\qquad\forall m\leq 2\cdot k
	\end{align*}
	(Ohne Beweis.)
\end{bemerkung}

Analoge Resultate zu Theorem \ref{theorem6.1EigenschaftenDerFTCF} für Fourier-Transformation einer Funktion $f\in L_1$:

\begin{korollar}\label{korollar6.3}
	Sei $f\in L_1(\R^d)$, $b\in\R^d$, $A\in\R^{d\times d}$ und $\alpha\in\N_0^d$ ein MI. Dann gilt:
	\begin{enumerate}[label=(\alph*)]
		\item $\begin{aligned}[t]
			g(x):=f(x+b) 
			\hspace{100pt}
			\implies \hat{g}(\xi)=\exp\big(-i\cdot b^T\cdot\xi\big)\cdot\hat{f}(\xi)
		\end{aligned}$
		\item $\begin{aligned}
			g(x):=\exp\big(i\cdot b^T\cdot x\big)\cdot f(x) 
			\hspace{45pt}
			\implies \hat{g}(\xi)=\hat{f}(\xi+b)
		\end{aligned}$
		\item $\begin{aligned}
			g(x):=f(A\cdot x)\mit \det(A)>0 
			\hspace{24pt}
			\implies \hat{g}(\xi)=\frac{1}{\det(A)}\cdot\hat{f}\big(A^{-T}\cdot\xi\big)
		\end{aligned}$
		\item $\begin{aligned}
			g(x):=(i\cdot x)^\alpha\cdot f(x)\mit g\in L_1 
			\hspace{23pt}
			\implies \hat{g}(\xi)=\partial^\alpha\hat{f}(\xi)
		\end{aligned}$
		\item $\begin{aligned}
			g(x):=\partial^\alpha f(x)\mit g\in C_\infty\cap L_1 
			\hspace{22pt}
			\implies \hat{g}(\xi)=(-i\cdot\xi)^\alpha\cdot\hat{f}(\xi)
		\end{aligned}$
	\end{enumerate}
\end{korollar}

\begin{bemerkung}
	\begin{align*}
		C_\infty:=\left\lbrace f:\R^d\to\C:f\text{ stetig und }\lim\limits_{|x|\to\infty}f(x)=0\right\rbrace
	\end{align*}
\end{bemerkung}

Zwei weitere wichtige Resultate zu charakteristischen Funktionen:
\begin{itemize}
	\item Faltungsformel
	\item Charakterisierung der Unabhängigkeit
\end{itemize}

\begin{theorem}\label{theorem6.4}\
	\begin{enumerate}[label=(\alph*)]
		\item Sei $X,Y$ unabhängige, $\R^d$-wertige Zufallsvariablen. Dann gilt:
		\begin{align*}
			\Phi_{X+Y}(\xi)=\Phi_X(\xi)\cdot\Phi_Y(\xi)\qquad\forall\xi\in\R^d
		\end{align*}
		\item Seien $f,g\in L_1(\R^d)$. Dann gilt:
		\begin{align*}
			\big(\widehat{f\ast g}\big)(\xi)=\hat{f}(\xi)\cdot\hat{g}(\xi)
		\end{align*}
	\end{enumerate}
\end{theorem}

\begin{bemerkung}
	Faltung:
	\begin{align*}
		(f\ast g)(x):=\int\limits_{\R^d}f(y)\cdot g(x-y)\d y
	\end{align*}
	Sei $f$ Dichte von $X$ ung $g$ Dichte von $Y$. Dann ist $f\ast g$ die Dichte von $X+Y$.
\end{bemerkung}

\begin{proof}
	\underline{Zeige (a):}
	\begin{align*}
		\Phi_{X+Y}(\xi)
		&=\E\Big[\exp(i\cdot\xi^T\cdot(X+Y)\Big] \\
		&=\E\Big[\exp(i\cdot\xi^T\cdot X)\cdot\exp(i\cdot\xi^T\cdot Y)\Big]\\
		\overset{X\unab Y}&{=}
		\E\Big[\exp(i\cdot\xi^T\cdot X)\Big]\cdot\E\Big[\exp(i\cdot\xi^T\cdot Y)\Big]\\
		&=\Phi_X(\xi)\cdot\Phi_Y(\xi)
	\end{align*}
	\underline{Zeige (b):}
	\begin{align*}
		\widehat{f\ast g}(\xi)
		&=\int\limits_{\R^d}\exp(i\cdot\xi^T\cdot x)\cdot(f\ast g)(x)\d x\\
		&=\int\limits_{\R^d}\exp(i\cdot\xi^T\cdot x)\cdot\int\limits_{\R^d}f(y)\cdot g(x-y)\d y\d x\\
		&=\int\limits_{\R^d}\int\limits_{\R^d}\exp(i\cdot\xi^T\cdot y)\cdot\exp(i\cdot\xi^T\cdot(x-y))\cdot f(y)\cdot g(x)\d y\d x\\
		&\overset{(\ast)}{=}
		\int\limits_{\R^d}\exp(i\cdot\xi^T\cdot y)\cdot f(y)\d y\cdot\int\limits_{\R^d}\exp(i\cdot\xi^T\cdot zu)\cdot g(z)\d z\\
		&=\hat{f}(\xi)\cdot\hat{g}(\xi)
	\end{align*}
	Bei $(\ast)$ wird substituiert: $z=x-y$, $\d z=\d x$
\end{proof}

Anwendung: Additionstheoreme für Normalverteilung, Poissonverteilung etc.

\begin{beisp}\
	\begin{itemize}
		\item $X\sim\text{Poi}(\lambda_1),~Y\sim\text{Poi}(\lambda_2),~X\unab Y$. Dann gilt:
		\begin{align*}
			\Phi_{X+Y}(\xi)
			&=\Phi_X(\xi)\cdot\Phi_Y(\xi)\\
			&=\exp\Big(\lambda_1\cdot\big(\exp(i\cdot\xi)-1\big)-\lambda_2\cdot\big(\exp(i\cdot\xi)-1\big)\Big)\\
			&=\exp\Big(\big(\lambda_1+\lambda_2\big)\cdot\big(\exp(i\cdot\xi)-1\big)\Big)\\
			&\implies X+Y\sim\text{Poi}(\lambda_1+\lambda_2)
		\end{align*}
		\item $X\sim\mathcal{N}(\mu_1,\sigma_1^2),~Y\sim\mathcal{N}(\mu_2,\sigma_2^2),~X\unab Y$. Dann gilt:
		\begin{align*}
			\Phi_{X+Y}(\xi)
			&=\Phi_X(\xi)\cdot\Phi_Y(\xi)\\
			&=\exp\left(i\cdot\xi\cdot\mu_1-\sigma_1^2\cdot\frac{\xi^2}{2}+i\cdot\xi\cdot\mu_2-\sigma_2^2\cdot\frac{\xi^2}{2}\right)\\
			&=\exp\left(i\cdot\xi\cdot(\mu_1+\mu_2)-(\sigma_1^2+\sigma_2^2)\cdot\frac{\xi^2}{2}\right)\\
			&\implies
			X+Y\sim\mathcal{N}(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)
		\end{align*}
		\item $X\sim\text{Exp}(\lambda_1),~Y\sim\text{Exp}(\lambda_2),~X\unab Y$. Dann gilt:
		\begin{align*}
			\Phi_{X+Y}(\xi)
			&=\Phi_X(\xi)\cdot\Phi_Y(\xi) \\
			&=\frac{\lambda_1}{\lambda_1-i\cdot u}\cdot\frac{\lambda_2}{\lambda_2-i\cdot u} \\
			&=\frac{\lambda_1\cdot\lambda_2}{(\lambda_1-i\cdot u)\cdot(\lambda_2-i\cdot u)}\\
			&\implies X+Y\text{ \ul{nicht} Exponentialverteilt}
		\end{align*}
	\end{itemize}
\end{beisp}

\begin{bemerkung}
	Hierbei haben wir den Eindeutigkeitssatz vorweggenommen:\\
	Die Charakteristische Funktion $\Phi_X(\xi)$ charakterisiert die Verteilung von $X$ eindeutig, d.h.:
	\begin{align*}
		\Big(\forall\xi\in\R^d:\Phi_X(\xi)=\Phi_Y(\xi)\Big)\Longleftrightarrow X\sim Y
	\end{align*}
	Beweis folgt in Kapitel 7.
\end{bemerkung}

\begin{theorem}[Charakterisierung der Unabhängigkeit]\label{theorem6.5CharakterisierungDerUnabhaengigkeit}\enter
	Seien $X$ und $Y$ zwei $\R^{d_1}$- bzw. $\R^{d_2}$-wertige Zufallsvariablen. Dann gilt:
	\begin{align*}
		X\unab Y\Longleftrightarrow\Big(\forall\xi\in\R^{d_1},\forall \eta\in\R^{d_2}:\Phi_{(X,Y)}\underbrace{(\xi,\eta)}_{\in\R^{d_1+d_2}}=\Phi_X(\xi)\cdot\Phi_Y(\eta)\Big)
	\end{align*}
\end{theorem}

\begin{proof}
	\underline{Zeige "$\implies$": (einfach)}
	\begin{align*}
		\Phi_{(X,Y)}(\xi,\eta)
		&=\E\Big[\exp\big(i\cdot(X,Y)^T\cdot(\xi,\eta)\big)\Big]\\
		&=\E\big[\exp\big(i\cdot X^T\cdot\xi+i\cdot Y^T\cdot \eta\big)\Big]\\
		\overset{X\unab Y}&=
		\E\Big[\exp\big(i\cdot X^T\cdot\xi\big)\Big]\cdot\E\Big[\exp\big(i\cdot Y^T\cdot \eta\big)\Big]\\
		&=\Phi_X(\xi)\cdot\Phi_Y(\eta)
	\end{align*}

	\underline{Zeige "$\Longleftarrow$":}\\
	Wir konstruieren (Stichwort Produktraum!) $\tilde{X}$ und $\tilde{Y}$ mit $\tilde{X}\sim X$ und $\tilde{Y}\sim Y$ so, dass $\tilde{X}\unab\tilde{Y}$. Aus $\tilde{X}\sim X$ und $\tilde{Y}\sim Y$ folgt, das $(\tilde{X},\tilde{Y})$ die gleiche Randverteilung wie $(X,Y)$ besitzt. Es gilt:
	\begin{align*}
		\Phi_{(X,Y)}(\xi,\eta)
		\overset{\text{Vor}}&=
		\Phi_X(\xi)\cdot\Phi_Y(\eta)
		=\Phi_{\tilde{X}}(\xi)\cdot\Phi_{\tilde{Y}}(\eta)
		\stackrelnew{\text{Teil 1}}{\tilde{X}\unab\tilde{Y}}{=}
		\Phi_{(\tilde{X},\tilde{Y})}(\xi,\eta)\qquad\forall\xi\in\R^{d_1},\eta\in\R^{d_2}
	\end{align*}
	Mit dem Eindeutigkeitssatz folgt $(X,Y)\sim(\tilde{X},\tilde{Y})\implies X\unab Y$
\end{proof}

